"""
Test script for the refactored AdvancedCrawler to demonstrate modular design.
"""

import json
from advanced_crawler_refactored import (
    AdvancedCrawlerRefactored,
    create_javascript_crawler,
    create_static_crawler,
    create_hybrid_crawler
)


def test_crawler_creation():
    """Test different crawler creation methods."""
    print("ğŸ§ª Testing crawler creation methods...")
    
    # Test basic creation
    basic_crawler = AdvancedCrawlerRefactored()
    print(f"âœ… Basic crawler created: {basic_crawler}")
    
    # Test factory methods
    js_crawler = create_javascript_crawler()
    print(f"âœ… JavaScript crawler created: {js_crawler}")
    
    static_crawler = create_static_crawler()
    print(f"âœ… Static crawler created: {static_crawler}")
    
    hybrid_crawler = create_hybrid_crawler()
    print(f"âœ… Hybrid crawler created: {hybrid_crawler}")
    
    # Test domain-specific creation
    alibaba_crawler = AdvancedCrawlerRefactored.create_for_domain("alibaba.ir")
    print(f"âœ… Alibaba-optimized crawler created: {alibaba_crawler}")
    
    print()


def test_crawler_configuration():
    """Test crawler configuration and strategy selection."""
    print("âš™ï¸  Testing crawler configuration...")
    
    # Test with custom configuration
    config = {
        "prefer_javascript": True,
        "timeout": 45,
        "headless": True,
        "save_dir": "./test_pages"
    }
    
    crawler = AdvancedCrawlerRefactored(config)
    print(f"âœ… Custom configured crawler: {crawler}")
    
    # Test strategy selection
    test_urls = [
        "https://alibaba.ir",
        "https://flytoday.ir", 
        "https://wikipedia.org",
        "https://github.com"
    ]
    
    for url in test_urls:
        if crawler.validate_url(url):
            strategy = crawler.choose_crawling_strategy(url)
            js_required = crawler.is_javascript_required(url)
            print(f"  URL: {url}")
            print(f"    Strategy: {strategy.value}")
            print(f"    JS Required: {js_required}")
    
    print()


def test_modular_components():
    """Test individual modular components."""
    print("ğŸ”§ Testing modular components...")
    
    crawler = AdvancedCrawlerRefactored()
    
    # Test component initialization
    print(f"âœ… MetadataExtractor initialized: {type(crawler.metadata_extractor).__name__}")
    print(f"âœ… ContentAnalyzer initialized: {type(crawler.content_analyzer).__name__}")
    print(f"âœ… ResourceExtractor initialized: {type(crawler.resource_extractor).__name__}")
    print(f"âœ… SeleniumHandler (lazy): {crawler.selenium_handler is None}")
    
    # Test observer pattern
    def progress_callback(message):
        print(f"  ğŸ“‹ Progress: {message}")
    
    crawler.set_progress_callback(progress_callback)
    crawler._notify_progress("Testing observer pattern")
    
    print()


def test_error_handling():
    """Test error handling and validation."""
    print("ğŸš¨ Testing error handling...")
    
    crawler = AdvancedCrawlerRefactored()
    
    # Test URL validation
    invalid_urls = ["", "not-a-url", "ftp://example.com", "javascript:alert('test')"]
    valid_urls = ["https://example.com", "http://test.local"]
    
    for url in invalid_urls:
        is_valid = crawler.validate_url(url)
        print(f"  âŒ Invalid URL '{url}': {is_valid}")
    
    for url in valid_urls:
        is_valid = crawler.validate_url(url)
        print(f"  âœ… Valid URL '{url}': {is_valid}")
    
    print()


def test_factory_pattern():
    """Test factory pattern implementation."""
    print("ğŸ­ Testing factory pattern...")
    
    # Test domain-specific optimizations
    domains = ["alibaba.ir", "flytoday.ir", "wikipedia.org", "github.com", "unknown.com"]
    
    for domain in domains:
        crawler = AdvancedCrawlerRefactored.create_for_domain(domain)
        print(f"  ğŸ·ï¸  Domain: {domain}")
        print(f"    Prefer JS: {crawler.prefer_javascript}")
        print(f"    Timeout: {crawler.timeout}")
        print(f"    Headless: {crawler.get_config('headless', 'default')}")
    
    print()


def test_stats_and_monitoring():
    """Test statistics and monitoring features."""
    print("ğŸ“Š Testing statistics and monitoring...")
    
    crawler = AdvancedCrawlerRefactored()
    
    # Test initial stats
    stats = crawler.get_crawling_stats()
    print(f"  Initial stats: {json.dumps(stats, indent=2)}")
    
    # Test required fields
    required_fields = crawler.get_required_fields()
    print(f"  Required fields: {required_fields}")
    
    # Test status tracking
    print(f"  Initial status: {crawler.status.value}")
    print(f"  Crawler type: {crawler.crawler_type.value}")
    print(f"  Error count: {len(crawler.errors)}")
    
    print()


def demonstrate_design_patterns():
    """Demonstrate design patterns in action."""
    print("ğŸ¯ Demonstrating design patterns...")
    
    # Strategy Pattern
    print("  Strategy Pattern:")
    crawler = AdvancedCrawlerRefactored()
    for url in ["https://alibaba.ir", "https://wikipedia.org"]:
        strategy = crawler.choose_crawling_strategy(url)
        print(f"    {url} â†’ {strategy.value}")
    
    # Factory Pattern
    print("  Factory Pattern:")
    js_crawler = create_javascript_crawler()
    static_crawler = create_static_crawler()
    print(f"    JavaScript Crawler: prefer_js={js_crawler.prefer_javascript}")
    print(f"    Static Crawler: prefer_js={static_crawler.prefer_javascript}")
    
    # Observer Pattern
    print("  Observer Pattern:")
    def observer_callback(message):
        print(f"    ğŸ“¡ Observed: {message}")
    
    crawler.set_progress_callback(observer_callback)
    crawler._notify_progress("Testing observer pattern")
    
    # Template Method Pattern (demonstrated through interface)
    print("  Template Method Pattern:")
    print(f"    Crawler implements {len(crawler.get_required_fields())} required methods")
    
    print()


def main():
    """Run all tests to demonstrate the refactored crawler."""
    print("ğŸš€ Testing Refactored AdvancedCrawler")
    print("=" * 50)
    
    try:
        test_crawler_creation()
        test_crawler_configuration()
        test_modular_components()
        test_error_handling()
        test_factory_pattern()
        test_stats_and_monitoring()
        demonstrate_design_patterns()
        
        print("âœ… All tests completed successfully!")
        print("\nğŸ“‹ Summary:")
        print("  âœ… Modular design with separated concerns")
        print("  âœ… Strategy pattern for crawling approach")
        print("  âœ… Observer pattern for progress tracking")
        print("  âœ… Factory pattern for specialized crawlers")
        print("  âœ… Template method pattern via interfaces")
        print("  âœ… Comprehensive error handling")
        print("  âœ… Configuration-driven behavior")
        
    except Exception as e:
        print(f"âŒ Test failed: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 