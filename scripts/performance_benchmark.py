#!/usr/bin/env python3
"""
Performance Benchmarking Tool Ø¨Ø±Ø§ÛŒ FlightioCrawler
Ø§ÛŒÙ† Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ Ø±Ø§ ØªØ³Øª Ùˆ Ø¨Ù†Ú†Ù…Ø§Ø±Ú© Ù…ÛŒâ€ŒÚ©Ù†Ø¯
"""

import asyncio
import time
import statistics
import random
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
import json
import argparse
from pathlib import Path
import psycopg2
from psycopg2.extras import RealDictCursor
import concurrent.futures
import threading
from contextlib import contextmanager
import sys
import os

# Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† path Ù¾Ø±ÙˆÚ˜Ù‡
sys.path.append(str(Path(__file__).parent.parent))

from config import config
from data_manager import DataManager
from monitoring.db_performance_monitor import DatabasePerformanceMonitor
import logging

# ØªÙ†Ø¸ÛŒÙ… logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@dataclass
class BenchmarkResult:
    """Ù†ØªÛŒØ¬Ù‡ ÛŒÚ© ØªØ³Øª benchmark"""
    test_name: str
    duration: float
    queries_per_second: float
    total_queries: int
    avg_response_time: float
    min_response_time: float
    max_response_time: float
    percentile_95: float
    success_rate: float
    error_count: int
    concurrent_users: int
    memory_usage: Optional[float] = None
    cpu_usage: Optional[float] = None

@dataclass
class BenchmarkConfig:
    """ØªÙ†Ø¸ÛŒÙ…Ø§Øª benchmark"""
    concurrent_users: int = 10
    test_duration: int = 60  # seconds
    queries_per_user: int = 100
    warm_up_time: int = 10  # seconds
    cool_down_time: int = 5  # seconds
    include_write_operations: bool = True
    include_complex_queries: bool = True
    
class DatabaseBenchmark:
    """Ú©Ù„Ø§Ø³ Ø§ØµÙ„ÛŒ Ø¨Ø±Ø§ÛŒ benchmark Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡"""
    
    def __init__(self, config_obj: BenchmarkConfig):
        self.config = config_obj
        self.data_manager = DataManager()
        self.monitor = DatabasePerformanceMonitor()
        self.results: List[BenchmarkResult] = []
        self.sample_airports = ['THR', 'IKA', 'MHD', 'IST', 'DXB', 'LHR', 'CDG', 'FRA']
        self.sample_airlines = ['IR', 'W5', 'EP', 'TK', 'EK', 'QR', 'LH', 'AF']
        
    def generate_sample_data(self, count: int = 1000) -> None:
        """ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡ Ø¨Ø±Ø§ÛŒ ØªØ³Øª"""
        logger.info(f"ØªÙˆÙ„ÛŒØ¯ {count} Ø±Ú©ÙˆØ±Ø¯ Ø¯Ø§Ø¯Ù‡ Ù†Ù…ÙˆÙ†Ù‡...")
        
        sample_flights = []
        base_time = datetime.now() + timedelta(days=1)
        
        for i in range(count):
            origin = random.choice(self.sample_airports)
            destination = random.choice([a for a in self.sample_airports if a != origin])
            airline = random.choice(self.sample_airlines)
            
            departure_time = base_time + timedelta(
                days=random.randint(0, 30),
                hours=random.randint(0, 23),
                minutes=random.randint(0, 59)
            )
            
            flight_data = {
                'site_1': [{
                    'airline': airline,
                    'flight_number': f"{airline}{random.randint(100, 999)}",
                    'origin': origin,
                    'destination': destination,
                    'departure_time': departure_time.isoformat(),
                    'arrival_time': (departure_time + timedelta(hours=random.randint(1, 8))).isoformat(),
                    'price': random.uniform(100000, 5000000),
                    'currency': 'IRR',
                    'seat_class': random.choice(['economy', 'business', 'first']),
                    'aircraft_type': random.choice(['A320', 'B737', 'A380', 'B777']),
                    'duration_minutes': random.randint(60, 480),
                    'flight_type': 'scheduled',
                    'source_url': f'https://example.com/flight/{i}'
                }]
            }
            
            sample_flights.append(flight_data)
            
            # batch insert Ù‡Ø± 100 Ø±Ú©ÙˆØ±Ø¯
            if len(sample_flights) >= 100:
                self.data_manager.store_flights({'batch': [f for fd in sample_flights for f in fd['site_1']]})
                sample_flights = []
        
        # insert Ø¨Ø§Ù‚ÛŒâ€ŒÙ…Ø§Ù†Ø¯Ù‡ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§
        if sample_flights:
            self.data_manager.store_flights({'batch': [f for fd in sample_flights for f in fd['site_1']]})
            
        logger.info("ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡ ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯")

    def run_simple_queries(self, user_id: int, queries_count: int) -> List[float]:
        """Ø§Ø¬Ø±Ø§ÛŒ Ú©ÙˆØ¦Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø¯Ù‡"""
        response_times = []
        
        for _ in range(queries_count):
            start_time = time.time()
            
            try:
                # Ú©ÙˆØ¦Ø±ÛŒ Ø³Ø§Ø¯Ù‡: Ø¬Ø³ØªØ¬ÙˆÛŒ Ù¾Ø±ÙˆØ§Ø²Ù‡Ø§
                origin = random.choice(self.sample_airports)
                destination = random.choice([a for a in self.sample_airports if a != origin])
                
                with self.data_manager.get_session() as session:
                    from data_manager import Flight
                    flights = session.query(Flight).filter(
                        Flight.origin == origin,
                        Flight.destination == destination
                    ).limit(50).all()
                    
                response_time = time.time() - start_time
                response_times.append(response_time)
                
            except Exception as e:
                logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ú©ÙˆØ¦Ø±ÛŒ Ø³Ø§Ø¯Ù‡ Ú©Ø§Ø±Ø¨Ø± {user_id}: {e}")
                response_times.append(float('inf'))
                
        return response_times

    def run_complex_queries(self, user_id: int, queries_count: int) -> List[float]:
        """Ø§Ø¬Ø±Ø§ÛŒ Ú©ÙˆØ¦Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾ÛŒÚ†ÛŒØ¯Ù‡"""
        response_times = []
        
        for _ in range(queries_count):
            start_time = time.time()
            
            try:
                # Ú©ÙˆØ¦Ø±ÛŒ Ù¾ÛŒÚ†ÛŒØ¯Ù‡: Ø¢Ù…Ø§Ø± Ù‚ÛŒÙ…Øª Ù¾Ø±ÙˆØ§Ø²Ù‡Ø§
                origin = random.choice(self.sample_airports)
                
                with self.data_manager.get_session() as session:
                    from data_manager import Flight
                    from sqlalchemy import func
                    
                    result = session.query(
                        func.avg(Flight.price).label('avg_price'),
                        func.min(Flight.price).label('min_price'),
                        func.max(Flight.price).label('max_price'),
                        func.count(Flight.id).label('flight_count')
                    ).filter(
                        Flight.origin == origin,
                        Flight.price > 0
                    ).first()
                    
                response_time = time.time() - start_time
                response_times.append(response_time)
                
            except Exception as e:
                logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ú©ÙˆØ¦Ø±ÛŒ Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ú©Ø§Ø±Ø¨Ø± {user_id}: {e}")
                response_times.append(float('inf'))
                
        return response_times

    def run_write_operations(self, user_id: int, operations_count: int) -> List[float]:
        """Ø§Ø¬Ø±Ø§ÛŒ Ø¹Ù…Ù„ÛŒØ§Øª Ù†ÙˆØ´ØªÙ†"""
        response_times = []
        
        for _ in range(operations_count):
            start_time = time.time()
            
            try:
                # Ø¹Ù…Ù„ÛŒØ§Øª Ù†ÙˆØ´ØªÙ†: Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† search query
                origin = random.choice(self.sample_airports)
                destination = random.choice([a for a in self.sample_airports if a != origin])
                
                search_params = {
                    'origin': origin,
                    'destination': destination,
                    'departure_date': '2024-06-01',
                    'passengers': random.randint(1, 4),
                    'seat_class': 'economy'
                }
                
                self.data_manager.store_search_query(
                    search_params,
                    result_count=random.randint(0, 100),
                    search_duration=random.uniform(0.5, 3.0),
                    cached=random.choice([True, False])
                )
                
                response_time = time.time() - start_time
                response_times.append(response_time)
                
            except Exception as e:
                logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¹Ù…Ù„ÛŒØ§Øª Ù†ÙˆØ´ØªÙ† Ú©Ø§Ø±Ø¨Ø± {user_id}: {e}")
                response_times.append(float('inf'))
                
        return response_times

    def run_user_simulation(self, user_id: int) -> Dict[str, List[float]]:
        """Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ ÛŒÚ© Ú©Ø§Ø±Ø¨Ø±"""
        logger.info(f"Ø´Ø±ÙˆØ¹ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ú©Ø§Ø±Ø¨Ø± {user_id}")
        
        results = {
            'simple_queries': [],
            'complex_queries': [],
            'write_operations': []
        }
        
        queries_per_test = self.config.queries_per_user // 3
        
        # Ú©ÙˆØ¦Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø¯Ù‡
        results['simple_queries'] = self.run_simple_queries(user_id, queries_per_test)
        
        # Ú©ÙˆØ¦Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾ÛŒÚ†ÛŒØ¯Ù‡
        if self.config.include_complex_queries:
            results['complex_queries'] = self.run_complex_queries(user_id, queries_per_test)
        
        # Ø¹Ù…Ù„ÛŒØ§Øª Ù†ÙˆØ´ØªÙ†
        if self.config.include_write_operations:
            results['write_operations'] = self.run_write_operations(user_id, queries_per_test)
        
        logger.info(f"Ù¾Ø§ÛŒØ§Ù† Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ú©Ø§Ø±Ø¨Ø± {user_id}")
        return results

    def calculate_benchmark_result(self, test_name: str, all_response_times: List[float]) -> BenchmarkResult:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†ØªÛŒØ¬Ù‡ benchmark"""
        # Ø­Ø°Ù response time Ù‡Ø§ÛŒ Ù†Ø§Ù…Ø¹ØªØ¨Ø±
        valid_times = [t for t in all_response_times if t != float('inf')]
        
        if not valid_times:
            return BenchmarkResult(
                test_name=test_name,
                duration=0,
                queries_per_second=0,
                total_queries=0,
                avg_response_time=0,
                min_response_time=0,
                max_response_time=0,
                percentile_95=0,
                success_rate=0,
                error_count=len(all_response_times),
                concurrent_users=self.config.concurrent_users
            )
        
        total_queries = len(all_response_times)
        error_count = len(all_response_times) - len(valid_times)
        success_rate = len(valid_times) / total_queries if total_queries > 0 else 0
        
        total_duration = sum(valid_times)
        avg_response_time = statistics.mean(valid_times)
        min_response_time = min(valid_times)
        max_response_time = max(valid_times)
        percentile_95 = statistics.quantiles(valid_times, n=20)[18] if len(valid_times) >= 20 else max_response_time
        
        queries_per_second = len(valid_times) / total_duration if total_duration > 0 else 0
        
        return BenchmarkResult(
            test_name=test_name,
            duration=total_duration,
            queries_per_second=queries_per_second,
            total_queries=total_queries,
            avg_response_time=avg_response_time,
            min_response_time=min_response_time,
            max_response_time=max_response_time,
            percentile_95=percentile_95,
            success_rate=success_rate,
            error_count=error_count,
            concurrent_users=self.config.concurrent_users
        )

    def run_benchmark(self) -> List[BenchmarkResult]:
        """Ø§Ø¬Ø±Ø§ÛŒ benchmark Ø§ØµÙ„ÛŒ"""
        logger.info("Ø´Ø±ÙˆØ¹ benchmark Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡...")
        
        # warm-up
        logger.info("Ù…Ø±Ø­Ù„Ù‡ warm-up...")
        self.run_user_simulation(0)
        time.sleep(self.config.warm_up_time)
        
        # benchmark Ø§ØµÙ„ÛŒ
        logger.info(f"Ø´Ø±ÙˆØ¹ benchmark Ø¨Ø§ {self.config.concurrent_users} Ú©Ø§Ø±Ø¨Ø± Ù‡Ù…Ø²Ù…Ø§Ù†...")
        
        all_results = {
            'simple_queries': [],
            'complex_queries': [],
            'write_operations': []
        }
        
        # Ø§Ø¬Ø±Ø§ÛŒ Ù‡Ù…Ø²Ù…Ø§Ù† Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.config.concurrent_users) as executor:
            future_to_user = {
                executor.submit(self.run_user_simulation, i): i 
                for i in range(self.config.concurrent_users)
            }
            
            for future in concurrent.futures.as_completed(future_to_user):
                user_id = future_to_user[future]
                try:
                    user_results = future.result()
                    
                    # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù†ØªØ§ÛŒØ¬
                    for test_type, times in user_results.items():
                        all_results[test_type].extend(times)
                        
                except Exception as e:
                    logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ú©Ø§Ø±Ø¨Ø± {user_id}: {e}")
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†ØªØ§ÛŒØ¬ Ù†Ù‡Ø§ÛŒÛŒ
        benchmark_results = []
        
        for test_type, response_times in all_results.items():
            if response_times:
                result = self.calculate_benchmark_result(test_type, response_times)
                benchmark_results.append(result)
                
        # cool-down
        logger.info("Ù…Ø±Ø­Ù„Ù‡ cool-down...")
        time.sleep(self.config.cool_down_time)
        
        self.results = benchmark_results
        logger.info("benchmark ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯")
        
        return benchmark_results

    def generate_report(self, output_file: Optional[str] = None) -> Dict[str, Any]:
        """ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ benchmark"""
        if not self.results:
            logger.warning("Ù‡ÛŒÚ† Ù†ØªÛŒØ¬Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ú¯Ø²Ø§Ø±Ø´ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯")
            return {}
        
        # Ú¯Ø±ÙØªÙ† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø³ÛŒØ³ØªÙ…
        system_info = {
            'database_config': {
                'pool_size': config.DATABASE.POOL_SIZE,
                'max_overflow': config.DATABASE.MAX_OVERFLOW,
                'pool_timeout': config.DATABASE.POOL_TIMEOUT,
                'connection_string': config.DATABASE.connection_string
            },
            'benchmark_config': {
                'concurrent_users': self.config.concurrent_users,
                'test_duration': self.config.test_duration,
                'queries_per_user': self.config.queries_per_user,
                'include_write_operations': self.config.include_write_operations,
                'include_complex_queries': self.config.include_complex_queries
            }
        }
        
        # Ú¯Ø±ÙØªÙ† Ø§Ø·Ù„Ø§Ø¹Ø§Øª performance
        performance_snapshot = self.monitor.get_performance_snapshot()
        connection_pool_status = self.data_manager.get_connection_pool_status()
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ
        total_queries = sum(r.total_queries for r in self.results)
        avg_qps = sum(r.queries_per_second for r in self.results) / len(self.results)
        overall_success_rate = sum(r.success_rate * r.total_queries for r in self.results) / total_queries if total_queries > 0 else 0
        
        report = {
            'timestamp': datetime.now().isoformat(),
            'system_info': system_info,
            'performance_snapshot': performance_snapshot.__dict__,
            'connection_pool_status': connection_pool_status,
            'benchmark_results': [r.__dict__ for r in self.results],
            'summary': {
                'total_queries': total_queries,
                'average_qps': avg_qps,
                'overall_success_rate': overall_success_rate,
                'total_errors': sum(r.error_count for r in self.results),
                'test_categories': len(self.results)
            },
            'recommendations': self._generate_recommendations()
        }
        
        # Ø°Ø®ÛŒØ±Ù‡ Ú¯Ø²Ø§Ø±Ø´
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            logger.info(f"Ú¯Ø²Ø§Ø±Ø´ Ø¯Ø± {output_file} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
        
        return report

    def _generate_recommendations(self) -> List[str]:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¨Ù‡Ø¨ÙˆØ¯ Ø¹Ù…Ù„Ú©Ø±Ø¯"""
        recommendations = []
        
        for result in self.results:
            if result.avg_response_time > 1.0:
                recommendations.append(f"Ø²Ù…Ø§Ù† Ù¾Ø§Ø³Ø® {result.test_name} Ø¨Ø§Ù„Ø§ Ø§Ø³Øª ({result.avg_response_time:.2f}s) - Ø¨Ø±Ø±Ø³ÛŒ indexes")
            
            if result.success_rate < 0.95:
                recommendations.append(f"Ù†Ø±Ø® Ù…ÙˆÙÙ‚ÛŒØª {result.test_name} Ù¾Ø§ÛŒÛŒÙ† Ø§Ø³Øª ({result.success_rate:.2%}) - Ø¨Ø±Ø±Ø³ÛŒ Ø®Ø·Ø§Ù‡Ø§")
            
            if result.queries_per_second < 10:
                recommendations.append(f"QPS {result.test_name} Ù¾Ø§ÛŒÛŒÙ† Ø§Ø³Øª ({result.queries_per_second:.1f}) - Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú©ÙˆØ¦Ø±ÛŒâ€ŒÙ‡Ø§")
        
        # Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ú©Ù„ÛŒ
        connection_pool_status = self.data_manager.get_connection_pool_status()
        if connection_pool_status.get('checked_out', 0) > connection_pool_status.get('pool_size', 0) * 0.8:
            recommendations.append("Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² connection pool Ø¨Ø§Ù„Ø§ Ø§Ø³Øª - Ø§ÙØ²Ø§ÛŒØ´ pool size")
        
        return recommendations

    def print_summary(self):
        """Ú†Ø§Ù¾ Ø®Ù„Ø§ØµÙ‡ Ù†ØªØ§ÛŒØ¬"""
        if not self.results:
            print("Ù‡ÛŒÚ† Ù†ØªÛŒØ¬Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯")
            return
        
        print("\n" + "="*80)
        print("Ø®Ù„Ø§ØµÙ‡ Ù†ØªØ§ÛŒØ¬ Benchmark Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡")
        print("="*80)
        
        for result in self.results:
            print(f"\nğŸ“Š {result.test_name.upper()}:")
            print(f"   ğŸ“ˆ Ú©Ù„ Ú©ÙˆØ¦Ø±ÛŒâ€ŒÙ‡Ø§: {result.total_queries}")
            print(f"   âš¡ Ú©ÙˆØ¦Ø±ÛŒ Ø¯Ø± Ø«Ø§Ù†ÛŒÙ‡: {result.queries_per_second:.1f}")
            print(f"   â±ï¸  Ù…ØªÙˆØ³Ø· Ø²Ù…Ø§Ù† Ù¾Ø§Ø³Ø®: {result.avg_response_time:.3f}s")
            print(f"   ğŸ“‰ Ú©Ù…ØªØ±ÛŒÙ† Ø²Ù…Ø§Ù†: {result.min_response_time:.3f}s")
            print(f"   ğŸ“ˆ Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ø²Ù…Ø§Ù†: {result.max_response_time:.3f}s") 
            print(f"   ğŸ¯ 95% percentile: {result.percentile_95:.3f}s")
            print(f"   âœ… Ù†Ø±Ø® Ù…ÙˆÙÙ‚ÛŒØª: {result.success_rate:.2%}")
            print(f"   âŒ ØªØ¹Ø¯Ø§Ø¯ Ø®Ø·Ø§Ù‡Ø§: {result.error_count}")
        
        print(f"\nğŸ”§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª:")
        print(f"   ğŸ‘¥ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ù‡Ù…Ø²Ù…Ø§Ù†: {self.config.concurrent_users}")
        print(f"   ğŸ”„ Ú©ÙˆØ¦Ø±ÛŒ Ù‡Ø± Ú©Ø§Ø±Ø¨Ø±: {self.config.queries_per_user}")
        
        # Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª
        recommendations = self._generate_recommendations()
        if recommendations:
            print(f"\nğŸ’¡ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª:")
            for i, rec in enumerate(recommendations, 1):
                print(f"   {i}. {rec}")
        
        print("="*80)


def main():
    """ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ"""
    parser = argparse.ArgumentParser(description='Database Performance Benchmark')
    parser.add_argument('--users', type=int, default=10, help='ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ù‡Ù…Ø²Ù…Ø§Ù†')
    parser.add_argument('--queries', type=int, default=100, help='ØªØ¹Ø¯Ø§Ø¯ Ú©ÙˆØ¦Ø±ÛŒ Ù‡Ø± Ú©Ø§Ø±Ø¨Ø±')
    parser.add_argument('--duration', type=int, default=60, help='Ù…Ø¯Øª Ø²Ù…Ø§Ù† ØªØ³Øª (Ø«Ø§Ù†ÛŒÙ‡)')
    parser.add_argument('--output', type=str, help='ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ Ú¯Ø²Ø§Ø±Ø´')
    parser.add_argument('--generate-data', action='store_true', help='ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡')
    parser.add_argument('--data-count', type=int, default=1000, help='ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡')
    parser.add_argument('--no-writes', action='store_true', help='Ø¹Ø¯Ù… Ø§Ø¬Ø±Ø§ÛŒ Ø¹Ù…Ù„ÛŒØ§Øª Ù†ÙˆØ´ØªÙ†')
    parser.add_argument('--no-complex', action='store_true', help='Ø¹Ø¯Ù… Ø§Ø¬Ø±Ø§ÛŒ Ú©ÙˆØ¦Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾ÛŒÚ†ÛŒØ¯Ù‡')
    
    args = parser.parse_args()
    
    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª benchmark
    benchmark_config = BenchmarkConfig(
        concurrent_users=args.users,
        test_duration=args.duration,
        queries_per_user=args.queries,
        include_write_operations=not args.no_writes,
        include_complex_queries=not args.no_complex
    )
    
    # Ø§ÛŒØ¬Ø§Ø¯ benchmark
    benchmark = DatabaseBenchmark(benchmark_config)
    
    try:
        # ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡
        if args.generate_data:
            benchmark.generate_sample_data(args.data_count)
        
        # Ø§Ø¬Ø±Ø§ÛŒ benchmark
        results = benchmark.run_benchmark()
        
        # Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬
        benchmark.print_summary()
        
        # ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´
        report = benchmark.generate_report(args.output)
        
        if args.output:
            print(f"\nğŸ“„ Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ù…Ù„ Ø¯Ø± {args.output} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
        
    except KeyboardInterrupt:
        logger.info("benchmark ØªÙˆØ³Ø· Ú©Ø§Ø±Ø¨Ø± Ù…ØªÙˆÙ‚Ù Ø´Ø¯")
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ benchmark: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()