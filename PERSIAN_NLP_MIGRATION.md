# ğŸ”§ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Migration Ø§Ø² hazm Ø¨Ù‡ Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ù…Ø¯Ø±Ù† NLP ÙØ§Ø±Ø³ÛŒ

## ğŸ“‹ Ø¯Ù„ÛŒÙ„ ØªØºÛŒÛŒØ±

- **hazm** Ù†ÛŒØ§Ø² Ø¨Ù‡ `nltk==3.3` Ø¯Ø§Ø±Ø¯ Ú©Ù‡ Ø¯Ø§Ø±Ø§ÛŒ Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ Ø§Ø³Øª
- **crawl4ai** Ù†ÛŒØ§Ø² Ø¨Ù‡ `nltk>=3.9.1` Ø¯Ø§Ø±Ø¯
- Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ù…Ø¯Ø±Ù†â€ŒØªØ± Ùˆ Ø§Ù…Ù†â€ŒØªØ±

## ğŸ”„ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ

### 1. **spaCy** (Ø§ØµÙ„ÛŒ)
```python
# Ù‚Ø¨Ù„ (hazm)
from hazm import Normalizer, word_tokenize, sent_tokenize

# Ø¨Ø¹Ø¯ (spaCy)
import spacy
nlp = spacy.load("xx_ent_wiki_sm")  # Multilingual model
```

### 2. **parsivar** (Ø¨Ø±Ø§ÛŒ ØªÙˆÚ©Ù†Ø§ÛŒØ²ÛŒØ´Ù† ÙØ§Ø±Ø³ÛŒ)
```python
# parsivar Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ
from parsivar import Normalizer, Tokenizer

normalizer = Normalizer()
tokenizer = Tokenizer()
```

### 3. **persian-tools** (Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ú©Ù…Ú©ÛŒ)
```python
# Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ù‡Ø§ÛŒ Ø¹Ù…ÙˆÙ…ÛŒ ÙØ§Ø±Ø³ÛŒ
from persian_tools import digits, phone_number
```

## ğŸ› ï¸ Ù†Ø­ÙˆÙ‡ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ

### Ú©Ø¯ Ù‚Ø¯ÛŒÙ…ÛŒ (hazm):
```python
from hazm import Normalizer, word_tokenize, sent_tokenize

normalizer = Normalizer()
text = normalizer.normalize("Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ")
words = word_tokenize(text)
sentences = sent_tokenize(text)
```

### Ú©Ø¯ Ø¬Ø¯ÛŒØ¯ (spaCy + parsivar):
```python
import spacy
from parsivar import Normalizer, Tokenizer

# spaCy Ø¨Ø±Ø§ÛŒ NLP Ø¹Ù…ÙˆÙ…ÛŒ
nlp = spacy.load("xx_ent_wiki_sm")

# parsivar Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§Ø±Ø³ÛŒ
normalizer = Normalizer()
tokenizer = Tokenizer()

# Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ†
text = normalizer.normalize("Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ")
words = tokenizer.tokenize_words(text)
sentences = tokenizer.tokenize_sentences(text)

# ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ spaCy
doc = nlp(text)
for token in doc:
    print(token.text, token.pos_, token.lemma_)
```

## ğŸ“¦ Ù†ØµØ¨ Ù…Ø¯Ù„ spaCy ÙØ§Ø±Ø³ÛŒ

```bash
# Ù†ØµØ¨ Ù…Ø¯Ù„ Ú†Ù†Ø¯Ø²Ø¨Ø§Ù†Ù‡
python -m spacy download xx_ent_wiki_sm

# ÛŒØ§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø®ØªØµØ§ØµÛŒ ÙØ§Ø±Ø³ÛŒ (Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯)
python -m spacy download fa_core_news_sm
```

## ğŸ”§ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªØºÛŒÛŒØ±

1. **data/transformers/persian_text_processor.py**
2. **persian_processor.py**
3. **persian_text.py**
4. **multilingual_processor.py**

## âš ï¸ Ù†Ú©Ø§Øª Ù…Ù‡Ù…

- spaCy Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¢Ù…ÙˆØ²Ø´ Ø¯ÛŒØ¯Ù‡ Ø¯Ø§Ø±Ø¯
- parsivar Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø®Ø§Øµ ÙØ§Ø±Ø³ÛŒ Ø¨Ù‡ØªØ± Ø§Ø³Øª
- nltk 3.9+ Ø§Ù…Ù† Ùˆ Ø¨Ø§ crawl4ai Ø³Ø§Ø²Ú¯Ø§Ø± Ø§Ø³Øª
- Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ù‡ØªØ± Ø¨Ø§Ø´Ø¯

## ğŸ§ª ØªØ³Øª

Ù¾Ø³ Ø§Ø² migrationØŒ ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ± Ø±Ø§ Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯:
```bash
python -m pytest tests/test_persian_text_processor.py -v
``` 